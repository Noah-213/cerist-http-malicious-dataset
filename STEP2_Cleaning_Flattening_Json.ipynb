{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21002,"status":"ok","timestamp":1749248106981,"user":{"displayName":"Tarek Bennouar","userId":"05753099953120326546"},"user_tz":-60},"id":"EOulOEObZBkr","outputId":"3eed82f0-a92d-42fe-908e-807f93a4e883"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive not mounted, so nothing to flush and unmount.\n","Mounted at /content/drive\n"]}],"source":["\n","from google.colab import drive\n","import os\n","\n","# --- Unmount any existing Drive mount (if needed) ---\n","drive.flush_and_unmount()\n","\n","# --- (Optional) Clear local /content/drive mountpoint (disabled for safety) ---\n","drive_path = '/content/drive'\n","if os.path.exists(drive_path) and os.listdir(drive_path):\n","    print(\"Notice: /content/drive is not empty. Skipping automatic deletion for safety.\")\n","    # Uncomment below to forcibly clear the mountpoint (NOT your actual Drive!)\n","    # !rm -rf /content/drive/*\n","\n","# --- Mount Google Drive ---\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["PYSHARK_DIR = \"/content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP1_json_enriched_pyshark\"\n","CLEANED_DIR = \"/content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED\"\n","CLEANED_FLATTENED_DIR = \"/content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED\"\n","os.makedirs(CLEANED_DIR, exist_ok=True)\n","os.makedirs(CLEANED_FLATTENED_DIR, exist_ok=True)"],"metadata":{"id":"pt0Q93WOrVf6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import json\n","\n","REQ_HEADER_KEEP = {\n","    \"http.host\", \"http.user_agent\", \"http.accept\", \"http.content_type\",\n","    \"http.content_length\", \"http.cookie\", \"http.referer\",\n","    \"http.authorization\", \"http.connection\"\n","}\n","RES_HEADER_KEEP = {\n","    \"http.server\", \"http.date\", \"http.content_type\", \"http.content_length\",\n","    \"http.content_length_header\", \"http.set_cookie\", \"http.connection\",\n","    \"http.cache_control\", \"http.location\", \"http.www_authenticate\",\n","    \"http.response.code\"     # <=== Ajout du code HTTP status ici !\n","}\n","\n","def clean_headers(headers, keep_keys):\n","    \"\"\"Garde uniquement les headers HTTP standards.\"\"\"\n","    return {k: v for k, v in headers.items() if k in keep_keys}\n","\n","def clean_pyshark_json_file(src_filepath, dst_filepath):\n","    \"\"\"Nettoie les artefacts Wireshark d'un fichier JSON enrichi PyShark et sauvegarde le résultat ailleurs.\"\"\"\n","    with open(src_filepath, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    for entry in data:\n","        # Nettoie les headers si présents\n","        if 'req_headers' in entry:\n","            entry['req_headers'] = clean_headers(entry['req_headers'], REQ_HEADER_KEEP)\n","        if 'res_headers' in entry:\n","            entry['res_headers'] = clean_headers(entry['res_headers'], RES_HEADER_KEEP)\n","        # (le reste des champs n'est pas modifié)\n","\n","    # S'assurer que le dossier destination existe\n","    os.makedirs(os.path.dirname(dst_filepath), exist_ok=True)\n","    with open(dst_filepath, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(data, f, indent=2, ensure_ascii=False)\n","    print(f\"Sauvé : {dst_filepath}\")\n","\n","def clean_all_pyshark_files(pyshark_dir, cleaned_dir):\n","    \"\"\"Nettoie tous les fichiers JSON d'un dossier PyShark et sauve dans un dossier de sortie.\"\"\"\n","    os.makedirs(cleaned_dir, exist_ok=True)\n","    for filename in os.listdir(pyshark_dir):\n","        if filename.endswith(\".json\"):\n","            src_filepath = os.path.join(pyshark_dir, filename)\n","            dst_filepath = os.path.join(cleaned_dir, filename)\n","            clean_pyshark_json_file(src_filepath, dst_filepath)\n","\n","# === Exécution ===\n","clean_all_pyshark_files(PYSHARK_DIR, CLEANED_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"agnrxECIrNHN","executionInfo":{"status":"ok","timestamp":1749248184637,"user_tz":-60,"elapsed":4457,"user":{"displayName":"Tarek Bennouar","userId":"05753099953120326546"}},"outputId":"bb0106dc-f5df-4397-fe13-8fdb9473b23a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/xml_pyshark.json\n","Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/lfi_pyshark.json\n","Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/ssti_pyshark.json\n","Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/cmdinj_pyshark.json\n","Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/xss_pyshark.json\n","Sauvé : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED/sql_pyshark.json\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","\n","def flatten_entry(entry):\n","    flat = {}\n","    # Champs principaux\n","    for field in [\n","        \"attack_tag\", \"src_ip\", \"dst_ip\", \"src_port\", \"dst_port\",\n","        \"req_method\", \"req_url\", \"req_body\", \"res_body\"\n","    ]:\n","        flat[field] = entry.get(field)\n","    # Headers de requête\n","    req_headers = entry.get(\"req_headers\", {})\n","    for k, v in req_headers.items():\n","        # Nettoie le nom: \"http.user_agent\" -> \"User_Agent\"\n","        k_flat = k.replace(\"http.\", \"\").replace(\".\", \"_\").replace(\"_\", \"-\").title().replace(\"-\", \"_\")\n","        flat[f\"req_header_{k_flat}\"] = v\n","    # Headers de réponse\n","    res_headers = entry.get(\"res_headers\", {})\n","    for k, v in res_headers.items():\n","        k_flat = k.replace(\"http.\", \"\").replace(\".\", \"_\").replace(\"_\", \"-\").title().replace(\"-\", \"_\")\n","        flat[f\"res_header_{k_flat}\"] = v\n","    return flat\n","\n","\n","def flatten_all_json_files(cleaned_dir, flattened_dir):\n","    \"\"\"Aplati tous les fichiers JSON du dossier cleaned_dir et les sauvegarde dans flattened_dir.\"\"\"\n","    os.makedirs(flattened_dir, exist_ok=True)\n","    for filename in os.listdir(cleaned_dir):\n","        if filename.endswith(\".json\"):\n","            src_path = os.path.join(cleaned_dir, filename)\n","            dst_path = os.path.join(flattened_dir, filename)\n","            with open(src_path, \"r\", encoding=\"utf-8\") as f:\n","                data = json.load(f)\n","            flat_data = [flatten_entry(e) for e in data]\n","            with open(dst_path, \"w\", encoding=\"utf-8\") as f:\n","                json.dump(flat_data, f, indent=2, ensure_ascii=False)\n","            print(f\"Fichier aplati : {dst_path}\")\n","\n","# === Exécution ===\n","flatten_all_json_files(CLEANED_DIR, CLEANED_FLATTENED_DIR)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bTga6gSvG2V","executionInfo":{"status":"ok","timestamp":1749248190124,"user_tz":-60,"elapsed":238,"user":{"displayName":"Tarek Bennouar","userId":"05753099953120326546"}},"outputId":"93ce9732-4d1c-4966-8185-14c06ee5b14b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/xml_pyshark.json\n","Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/lfi_pyshark.json\n","Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/ssti_pyshark.json\n","Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/cmdinj_pyshark.json\n","Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/xss_pyshark.json\n","Fichier aplati : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/json_CLEANED_FLATTENED/sql_pyshark.json\n"]}]},{"cell_type":"code","source":["import os\n","import json\n","\n","CLEANED_FLATTENED_DEDUP_DIR = \"/content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP\"\n","os.makedirs(CLEANED_FLATTENED_DEDUP_DIR, exist_ok=True)\n","\n","def deduplicate_json_file(src_path, dst_path, key_fields=None):\n","    \"\"\"\n","    Déduplique un fichier JSON (liste de dicts) sur les champs clé.\n","    Si key_fields est None, on déduplique sur l'ensemble des champs.\n","    \"\"\"\n","    with open(src_path, \"r\", encoding=\"utf-8\") as f:\n","        data = json.load(f)\n","\n","    if key_fields is None:\n","        # Déduplication sur tout le dict\n","        seen = set()\n","        unique_data = []\n","        for entry in data:\n","            # Utilisation d'un tuple ordonné pour que l'ordre des clés ne casse pas la déduplication\n","            hashable = tuple(sorted(entry.items()))\n","            if hashable not in seen:\n","                seen.add(hashable)\n","                unique_data.append(entry)\n","    else:\n","        # Déduplication seulement sur les champs choisis\n","        seen = set()\n","        unique_data = []\n","        for entry in data:\n","            hashable = tuple(entry.get(k) for k in key_fields)\n","            if hashable not in seen:\n","                seen.add(hashable)\n","                unique_data.append(entry)\n","\n","    with open(dst_path, \"w\", encoding=\"utf-8\") as f:\n","        json.dump(unique_data, f, indent=2, ensure_ascii=False)\n","    print(f\"Dédupliqué : {dst_path} ({len(data)} → {len(unique_data)} entrées)\")\n","\n","# === Exécution sur tout le dossier ===\n","for filename in os.listdir(CLEANED_FLATTENED_DIR):\n","    if filename.endswith(\".json\"):\n","        src_path = os.path.join(CLEANED_FLATTENED_DIR, filename)\n","        dst_path = os.path.join(CLEANED_FLATTENED_DEDUP_DIR, filename)\n","        # Tu peux choisir les clés à utiliser pour la déduplication :\n","        key_fields = [\"req_method\", \"req_url\", \"req_body\"]\n","        deduplicate_json_file(src_path, dst_path, key_fields)  # None = tous les champs\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jTGUObtwJ2eS","executionInfo":{"status":"ok","timestamp":1749248264477,"user_tz":-60,"elapsed":125,"user":{"displayName":"Tarek Bennouar","userId":"05753099953120326546"}},"outputId":"241e9c60-75c7-4e0b-abcd-136c7de35d9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/xml_pyshark.json (10 → 10 entrées)\n","Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/lfi_pyshark.json (671 → 661 entrées)\n","Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/ssti_pyshark.json (206 → 167 entrées)\n","Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/cmdinj_pyshark.json (77 → 64 entrées)\n","Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/xss_pyshark.json (154 → 154 entrées)\n","Dédupliqué : /content/drive/MyDrive/BINOME_WORK/STAGE_CERIST/DATA_FORMATING/STEP2_json_CLEANED_FLATTENED_DEDUP/sql_pyshark.json (171 → 160 entrées)\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNp+rbLlWTs86aOcAfvevG1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}